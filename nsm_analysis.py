"""
A bunch of functions for NSM analysis
"""
import numpy as np 


def pix_gen(data_struct):
    # Generate pixel limits
    # Data struct is the data struct generated by our 
    ds = data_struct
    X_pix_w = (ds.Xmax - ds.Xmin)/ds.Xpoints*ds.AoD_Xfactor
    Y_pix_w = (ds.Ymax - ds.Ymin)/ds.Ypoints*ds.AoD_Yfactor
    XStart = (ds.Xmin-ds.AoD_midpoint_X)*ds.AoD_Xfactor - X_pix_w/2
    YStart = (ds.Ymin-ds.AoD_midpoint_Y)*ds.AoD_Yfactor - Y_pix_w/2
    XEnd = (ds.Xmax-ds.AoD_midpoint_X)*ds.AoD_Xfactor + X_pix_w/2
    YEnd = (ds.Ymax-ds.AoD_midpoint_Y)*ds.AoD_Yfactor + Y_pix_w/2
    x_pix = np.arange(start=XStart, stop=XEnd, step=X_pix_w)
    y_pix = np.arange(start=YStart, stop=YEnd, step=Y_pix_w)

    return x_pix, y_pix


def pix_assign(x_pos, y_pos, x_nom, y_nom, x_pix, y_pix):
    # generate an X_Pix/Y_Pix sized array, every value is a list of
    # measurements that fall within that range.
    # This is where some of the brownian correction comes in!
    # Our arrays are zero-padded, so that will need to be removed in use.
    assert x_pos.size == y_pos.size
    pix_indecies = np.zeros((x_pix.size-1, y_pix.size-1, x_pos.size))
    domain_list = list()
    # Actual position assignment
    # For each pixel,
    for j in range(x_pix.size-1):
        for k in range(y_pix.size-1):
            # Run through all readings and append the ones that fit to the list
            for i in range(x_pos.size):
                if (x_pos[i] > x_pix[j] and
                    x_pos[i] < x_pix[j+1] and
                    y_pos[i] > y_pix[k] and
                    y_pos[i] < y_pix[k+1]):
                        domain_list.append(i)
        # Pad out our list to the correct size
            padded_list = np.pad(
                array=domain_list,
                pad_width=(0, x_pos.size-len(domain_list)),
                mode='constant',
                constant_values=0
                )
            pix_indecies[j, k, :] = padded_list